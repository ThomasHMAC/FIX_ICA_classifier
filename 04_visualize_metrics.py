import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from functools import partial
from pathlib import Path
import os

def extract_metrics(model_accuracy_path):
    """
    Extracts model performance metrics from a text file generated by FSL FIX's `-C` training command.

    This is typically used with files like:
        - HCP_hp2000_accuracy_results
        - model_accuracy_results

    Parameters:
        model_accuracy_path (str): Path to the accuracy results text file.

    Returns:
        pd.DataFrame: A DataFrame containing parsed performance metrics.
    """
    if model_accuracy_path.endswith("pyfix_model"):
        with open(model_accuracy_path) as f:
            lines = [line.strip() for line in f if line.strip()]

        # Find indexes for 'dataset' and 'mean' lines that mark data block
        dataset_idx = next((i for i, line in enumerate(lines) if line.lower().startswith("dataset")), None)
        mean_idx = next((i for i, line in enumerate(lines) if line.lower().startswith("mean")), None)

        if dataset_idx is None or mean_idx is None:
            raise ValueError("Cannot find 'Dataset' or 'Mean' section in the log file.")

        # Extract the relevant data block
        data_str = lines[dataset_idx:mean_idx]

        # Extract headers and thresholds
        header_line = data_str[0]
        threshold_line = data_str[1]
        data_rows = data_str[3:]  # Skip 'ID' line and two header lines

        # Parse column names from headers
        header_parts = header_line.split()[1:]     # skip 'Dataset'
        threshold_parts = threshold_line.split()[1:]
        metric_columns = [f"{metric}_thresh_{thresh}" for metric, thresh in zip(header_parts, threshold_parts)]
        columns = ['ID', 'Path'] + metric_columns

        # Parse the data rows into structured list
        data_parsed = []
        for row in data_rows:
            parts = row.strip().split(maxsplit=2)
            if len(parts) < 3:
                continue
            id_, path, values_str = parts
            values = list(map(float, values_str.split()))
            data_parsed.append([id_, path] + values)

        # Create DataFrame
        df = pd.DataFrame(data_parsed, columns=columns)

        # Get unique thresholds as integers
        thresholds = sorted(set(int(t) for t in threshold_parts))

        # Compute summary statistics
        summary_stats = []
        for thresh in thresholds:
            tnr = df[f'TNR_thresh_{thresh}']
            tpr = df[f'TPR_thresh_{thresh}']
            tpr_tnr = (3 * tpr + tnr) / 4

            summary_stats.append({
                'Threshold': thresh,
                'TPR_mean': tpr.mean(),
                'TPR_std': tpr.std(),
                'TNR_mean': tnr.mean(),
                'TNR_std': tnr.std(),
                'TPR_TNR_mean': tpr_tnr.mean(),
                'TPR_TNR_std': tpr_tnr.std()
            })

        return pd.DataFrame(summary_stats)
    
    elif model_accuracy_path.endswith("RData_results"):
        with open(model_accuracy_path) as f:
            lines = [line.strip() for line in f if line.strip()]
        idx = next((i for i, line in enumerate(lines) if line.lower().startswith("set")), None)

        data_str = lines[0:idx]
        data_float = [list(map(float, row.split())) for row in data_str]
        data_array = np.array(data_float)
        tpr_array = data_array[:, 0::2]  # every 2nd starting at 0
        tnr_array = data_array[:, 1::2]
        tpr_tnr_array = (3 * tpr_array + tnr_array) / 4
        tpr_mean = tpr_array.mean(axis=0)
        tpr_std = tpr_array.std(axis=0)
        tnr_mean= tnr_array.mean(axis=0)
        tnr_std = tnr_array.std(axis=0)
        tpr_tnr_mean = tpr_tnr_array.mean(axis=0)
        tpr_tnr_std = tpr_tnr_array.std(axis=0)
        return pd.DataFrame({
            'Threshold': [1, 2, 5, 10, 20, 30, 40, 50],
            'TPR_mean': tpr_mean,
            'TPR_std': tpr_std,
            'TNR_mean': tnr_mean,
            'TNR_std': tnr_std,
            'TPR_TNR_mean': tpr_tnr_mean,
            'TPR_TNR_std': tpr_tnr_std
        })
    else:
        raise ValueError("Unrecognized filename format")

def plot_model_performance(metrics_df, save_path=None, title="FIX Model Performance"):
    """
    Plots the performance of a FIX classifier model from a metrics DataFrame.

    Parameters:
        metrics_df (pd.DataFrame): DataFrame output from the extract_metrics function.
        save_path (str, optional): If provided, saves the plot to this path. Otherwise, displays the plot.

    Returns:
        None
    """
    fig, ax = plt.subplots(figsize=(10, 4))
    for col in metrics_df.columns:
        if col.endswith('_mean'):
            base_name = col[:-5]
            std_col = base_name + '_std'
            if std_col in metrics_df.columns:
                ax.errorbar(
                    metrics_df['Threshold'],
                    metrics_df[col],
                    yerr=metrics_df[std_col],
                    fmt='-o',
                    label=base_name
                )
    # Axes and legend formatting
    ax.set_xlabel('Threshold')
    ax.set_ylabel('Value')
    ax.set_title(title, loc='center', fontsize=14)

    # Adjust box size and place legend outside
    box = ax.get_position()
    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()

def _path_exists(path_str, parser):
    path = Path(path_str)
    if not path.exists():
        parser.error(f"The path '{path}' does not exist.")
    return path

def main():
    parser = argparse.ArgumentParser(
        description="Plot performance metrics from FSL FIX model training results."
    )
    PathExists = partial(_path_exists, parser=parser)
    parser.add_argument(
        "accuracy_txt",
        type=PathExists,
        help=(
            "Path to the FSL FIX accuracy results text file (e.g., 'HCP_hp2000_accuracy_results')"
        ),
    )
    parser.add_argument(
        "--save", type=str, default=None,
        help=(
            "Optional path to save the output plot as an image. "
            "If not specified, the plot will be saved alongside the accuracy results text file."
        )
    )
    parser.add_argument(
        "--title", type=str, default="FIX Model Performance",
        help="Title to display on the plot."
    )
    args = parser.parse_args()

    accuracy_f = args.accuracy_txt

    if args.save is None:
        stem = accuracy_f.stem
        default_filename = f"{stem}_performance.png"
        args.save = str(accuracy_f.parent / default_filename)
        print(f"[INFO] No --save argument provided. Plot will be saved to: {args.save}")

    df = extract_metrics(accuracy_f)
    plot_model_performance(df, save_path=args.save, title=args.title)

if __name__ == "__main__":
    main()